
# ğŸ§  **Structured AI Prompting System**

## ğŸ“˜ Overview

This document defines a **structured prompting framework** designed to help maintain focus and composure during high-pressure tasks â€” such as Kaggle competitions, debugging, or coding under time constraints.

It prevents â€œpanic promptingâ€ and ensures every AI interaction has a clear **goal, context, constraint, and output**.

> ğŸ¯ **Objective:**
> Stay calm, think precisely, and command the AI â€” not be controlled by it.

---

## âš™ï¸ **Prompt Template (Base Structure)**

### ğŸ§© **Prompt Format**

Use this 4-section format **every time you ask AI for code or strategy help.**


ğŸ¯ GOAL:
[Describe exactly what you want to achieve, not what you want to see.]

ğŸ“ CONTEXT:
[Explain the current situation â€” what variables, files, or stages exist.
Mention what youâ€™ve already tried.]

âš™ï¸ CONSTRAINTS:
[List what must NOT be changed or what must remain consistent.
Example: â€œDonâ€™t rename variablesâ€ or â€œKeep same function structure.â€]

ğŸ§¾ EXPECTED OUTPUT:
[Explain what kind of result you expect â€” code, explanation, step-by-step plan, etc.]

---

### ğŸ§  **Example (Kaggle Modeling Stage)**

ğŸ¯ GOAL:
Improve model performance from 0.78 â†’ 0.82 F1-score using tree-based ensemble.

ğŸ“ CONTEXT:
I already have `X_train`, `y_train`, `X_val`, `y_val` from the preprocessing pipeline.  
Models currently available: RandomForest, XGBoost, GradientBoosting.  
Evaluation metric = weighted F1-score.

âš™ï¸ CONSTRAINTS:
Donâ€™t modify the preprocessing code or feature_engineering() function.  
Model training time must stay under 10 minutes.  
Keep outputs compatible with evaluate_model().

ğŸ§¾ EXPECTED OUTPUT:
Modular Python code that builds a StackingClassifier using the three base models.  
Include evaluation step and print weighted F1-score.


---

### ğŸ§© **Example (Debugging Under Pressure)**

ğŸ¯ GOAL:
Fix error â€œValueError: could not convert string to floatâ€ that appears when predicting.

ğŸ“ CONTEXT:
I used a preprocessing pipeline with OneHotEncoder and trained a LinearRegression model.  
`X_train` works fine, but `X_test` prediction fails with that error.

âš™ï¸ CONSTRAINTS:
Donâ€™t rewrite the entire pipeline â€” only modify the test transformation part.  
Must keep the same model and variable names (`regressor`, `preprocessor`).

ğŸ§¾ EXPECTED OUTPUT:
Short Python fix (1â€“2 lines) that correctly preprocesses `X_test` before prediction,  
and brief explanation why the error happened.

---

## ğŸ§­ **Usage Flow (War-Time Prompt Discipline)**

| Step | Action                      | Purpose                                                   |
| ---- | --------------------------- | --------------------------------------------------------- |
| 1ï¸âƒ£  | **Stop. Breathe.**          | Interrupt panic mode before typing random questions.      |
| 2ï¸âƒ£  | **Write your GOAL.**        | Forces clarity â€” what are you *actually* trying to solve? |
| 3ï¸âƒ£  | **Add CONTEXT.**            | Helps AI give relevant, not generic responses.            |
| 4ï¸âƒ£  | **Set CONSTRAINTS.**        | Prevents the AI from breaking your notebook.              |
| 5ï¸âƒ£  | **Define EXPECTED OUTPUT.** | Keeps result usable and directly actionable.              |

---

## ğŸ“‹ **Common Prompt Patterns**

### ğŸ§± **1. Code Request**

For generating specific code blocks.


ğŸ¯ GOAL: Create preprocessing pipeline for mixed numeric and categorical data.
ğŸ“ CONTEXT: Dataset = df_train, target = 'price'.  
âš™ï¸ CONSTRAINTS: Donâ€™t rename variables or import unnecessary libraries.  
ğŸ§¾ EXPECTED OUTPUT: Scikit-learn pipeline code using ColumnTransformer.


### ğŸ§  **2. Concept Understanding**

For asking theoretical or strategic help.

ğŸ¯ GOAL: Understand when to use log transform on target variable.
ğŸ“ CONTEXT: My model underfits (RÂ² = 0.7) and target distribution is right-skewed.  
âš™ï¸ CONSTRAINTS: Keep explanation short, intuitive, and use dataset-related examples.  
ğŸ§¾ EXPECTED OUTPUT: Concise explanation + rule of thumb for applying log transform.


### âš™ï¸ **3. Error Fix**

For debugging AI-generated or competition code.

ğŸ¯ GOAL: Fix "shape mismatch" during ensemble stacking.
ğŸ“ CONTEXT: Using RandomForest, XGB, and LogisticRegression in StackingClassifier.  
âš™ï¸ CONSTRAINTS: Donâ€™t remove any base model. Keep same variable names.  
ğŸ§¾ EXPECTED OUTPUT: Short fix + reason of error.


### ğŸ§© **4. Strategy / Reflection**

For when lo bingung ambil keputusan.


ğŸ¯ GOAL: Decide whether to drop high-cardinality feature `model_name`.
ğŸ“ CONTEXT: Feature has 3,000 unique values and increases training time.
âš™ï¸ CONSTRAINTS: Assume this is a classification task.
ğŸ§¾ EXPECTED OUTPUT: Logical reasoning + simple rule of thumb (keep or drop).

---

## ğŸ§° **Mini Prompts Library (Quick Copy-Paste)**

| Scenario               | Ready-to-Use Prompt                                                                                                             |
| ---------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| âš™ï¸ Preprocessing       | â€œGenerate modular code for preprocessing mixed data (num + cat) using sklearn pipelines. Donâ€™t modify existing variable names.â€ |
| ğŸ§© Feature Engineering | â€œSuggest 3 new feature ideas based on EDA insights where target distribution differs across groups.â€                            |
| ğŸ§  Model Tuning        | â€œOptimize RandomForest parameters to improve F1-score under 10 min runtime.â€                                                    |
| ğŸš¨ Error Debug         | â€œExplain and fix error `could not convert string to float` during prediction step, without changing model logic.â€               |
| ğŸ“Š Evaluation          | â€œAdd cross-validation scoring (weighted F1) to my current evaluate_model() function.â€                                           |
| âš”ï¸ Strategy            | â€œCompare pros/cons of stacking vs soft-voting ensemble for multiclass classification.â€                                          |

---

## ğŸ§© **Optional: Quick Prompt Template (for daily use)**

Keep this pinned on top of your notebook or Notion page:

ğŸ¯ GOAL:
ğŸ“ CONTEXT:
âš™ï¸ CONSTRAINTS:
ğŸ§¾ EXPECTED OUTPUT:

---

## ğŸ’¡ **Best Practices**

1. **Never prompt emotionally.** Pause before typing â€” logic first, emotions later.
2. **Write the prompt in 2â€“4 lines max.** Clarity beats verbosity.
3. **Always include constraints.** This is what separates structured engineers from chaotic coders.
4. **Treat the AI as a junior assistant** â€” *you lead, it executes.*
5. **Save good prompts** â€” reuse them for future competitions (build your prompt bank).

---

## ğŸ Closing Note

> â€œIn chaos, structure wins.
> In pressure, precision wins.
> In competition, clarity wins.â€

This system isnâ€™t about writing better prompts â€”
itâ€™s about building the **mental algorithm** that keeps you calm, strategic, and in full command of your AI assistant.
