{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ab0270",
   "metadata": {},
   "source": [
    "# ðŸ§  Kaggle Competition Template â€“ Ensemble Learning (Multiclass)\n",
    "\n",
    "This notebook is optimized for structured ensemble learning competitions.  \n",
    "It supports baseline â†’ boosting â†’ voting/stacking.\n",
    "\n",
    "**Pipeline:**\n",
    "1. EDA (Quick)\n",
    "2. Preprocessing\n",
    "3. Feature Engineering\n",
    "4. Modeling (Multiple Models)\n",
    "5. Ensemble (Voting/Stacking)\n",
    "6. Evaluation (Accuracy/F1)\n",
    "7. Submission\n",
    "8. Experiment Log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fcd1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Optional ensemble models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Basic Info ===\n",
    "print(\"Dataset shape:\", df_train.shape)\n",
    "display(df_train.head(3))\n",
    "df_train.info()\n",
    "\n",
    "# === Missing Values ===\n",
    "missing = df_train.isna().sum().sort_values(ascending=False)\n",
    "missing = missing[missing > 0]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=missing.values, y=missing.index)\n",
    "plt.title(\"Missing Values per Feature\")\n",
    "plt.show()\n",
    "\n",
    "# === Target Distribution ===\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_train['target'])\n",
    "plt.title(\"Target Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Class proportions:\")\n",
    "print(df_train['target'].value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Feature Summary ===\n",
    "num_cols = df_train.select_dtypes(include=['int64','float64']).columns\n",
    "cat_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"Numerical features: {len(num_cols)}\")\n",
    "print(f\"Categorical features: {len(cat_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Correlation (Numerical) ===\n",
    "plt.figure(figsize=(10,8))\n",
    "corr = df_train[num_cols].corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=False)\n",
    "plt.title(\"Numerical Feature Correlation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Numerical Features vs Target ===\n",
    "for col in num_cols[:6]:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.boxplot(x='target', y=col, data=df_train)\n",
    "    plt.title(f\"{col} vs Target\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f597270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Categorical Features vs Target ===\n",
    "for col in cat_cols[:5]:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.countplot(x=col, hue='target', data=df_train)\n",
    "    plt.title(f\"{col} vs Target\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd34418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Outlier Detection ===\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.boxplot(data=df_train[num_cols])\n",
    "plt.title(\"Outlier Overview (Numerical Features)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quick Feature Importance (RF baseline) ===\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df_train['target'])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(df_train[num_cols].fillna(0), y_encoded)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=num_cols).sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x=importances.values[:10], y=importances.index[:10])\n",
    "plt.title(\"Top 10 Feature Importances (Quick RF Baseline)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48338761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Generic rules\n",
    "    if \"release_year\" in df.columns:\n",
    "        df[\"device_age\"] = 2025 - df[\"release_year\"].fillna(2025)\n",
    "\n",
    "    # Interaction (optional)\n",
    "    if all(col in df.columns for col in [\"cpu_tier\", \"gpu_tier\"]):\n",
    "        df[\"performance_score\"] = df[\"cpu_tier\"] * df[\"gpu_tier\"]\n",
    "    \n",
    "    # Domain-specific placeholders\n",
    "    # (edit per competition)\n",
    "    # if \"income\" in df.columns and \"expenses\" in df.columns:\n",
    "    #     df[\"savings_ratio\"] = df[\"income\"] / (df[\"expenses\"] + 1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2578c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(X, num_strategy=\"median\", scaler=\"standard\", cat_strategy=\"most_frequent\"):\n",
    "    num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "    num_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=num_strategy)),\n",
    "        (\"scaler\", StandardScaler() if scaler==\"standard\" else MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=cat_strategy)),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols)\n",
    "    ])\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a68bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    models = {\n",
    "        \"logreg\": LogisticRegression(max_iter=500),\n",
    "        \"rf\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
    "        \"xgb\": XGBClassifier(\n",
    "            n_estimators=400, learning_rate=0.05, random_state=42, \n",
    "            use_label_encoder=False, eval_metric='mlogloss'\n",
    "        ),\n",
    "        \"gb\": GradientBoostingClassifier(n_estimators=300, random_state=42),\n",
    "        \"svc\": SVC(probability=True, kernel='rbf')\n",
    "    }\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_voting_ensemble(models):\n",
    "    estimators = [(name, m) for name, m in models.items()]\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "    return voting_clf\n",
    "\n",
    "def build_stacking_ensemble(models):\n",
    "    estimators = [(name, m) for name, m in models.items()]\n",
    "    final_estimator = LogisticRegression(max_iter=500)\n",
    "    stack_clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\n",
    "    return stack_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af416f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb980c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, preprocessor, df_train, df_test):\n",
    "    X_train = df_train.drop(columns=[\"target\"])\n",
    "    y_train = df_train[\"target\"]\n",
    "    X_test = df_test.copy()\n",
    "    \n",
    "    X_train_proc = preprocessor.fit_transform(X_train, y_train)\n",
    "    X_test_proc = preprocessor.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_proc, y_train)\n",
    "    y_pred = model.predict(X_test_proc)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": df_test[\"id\"],\n",
    "        \"target\": y_pred\n",
    "    })\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"âœ… Submission saved: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1022ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def log_experiment(version, model_name, ensemble_type, acc, f1, notes):\n",
    "    with open(\"experiment_log.csv\", \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([version, model_name, ensemble_type, acc, f1, notes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1530dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Feature Engineering ===\n",
    "df_train = feature_engineering(df_train)\n",
    "df_test = feature_engineering(df_test)\n",
    "\n",
    "# === 2. Split Data ===\n",
    "X = df_train.drop(columns=[\"target\"])\n",
    "y = df_train[\"target\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# === 3. Preprocess ===\n",
    "preprocessor = build_preprocessor(X_train)\n",
    "X_train_proc = preprocessor.fit_transform(X_train, y_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "# === 4. Build Base Models ===\n",
    "models = build_models()\n",
    "\n",
    "# === 5. Build Ensemble ===\n",
    "voting_model = build_voting_ensemble(models)\n",
    "stacking_model = build_stacking_ensemble(models)\n",
    "\n",
    "# === 6. Evaluate (example with stacking) ===\n",
    "acc, f1 = evaluate_model(stacking_model, X_train_proc, y_train, X_val_proc, y_val)\n",
    "\n",
    "# === 7. Log Experiment ===\n",
    "log_experiment(\"v1\", \"stacking\", \"LogReg Meta\", acc, f1, \"Baseline ensemble\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datmin (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
